//! Run global parameter optimization and day forward chaining on the pre-evaluated data.
//!
//! This program consumes the `eval_results_*.json` files generated by `param-grid-search`.
//!
//! It produces `./global_opt_results_{configuration}{extra}.json` and `./dfc_results_{configuration}{extra}.json` files.

#![deny(unused_import_braces, unused_qualifications)]

use color_eyre::eyre::{eyre, Result};
use evaluation::{ok, DataConfiguration, EvaluationResults, Location};
use rayon::prelude::*;
use std::collections::BTreeMap;
use std::path::PathBuf;

#[derive(Debug, clap::Parser)]
struct CliArgs {
    /// Identifier to select input files and name output files
    ///
    /// This identifier must occur in the path of the input files.
    /// This allows filtering a subset of all available files.
    /// The value is also embedded in the output file names.
    #[clap(long)]
    configuration: String,
    /// Extra value added to the output filename
    #[clap(long)]
    extra: Option<String>,
    /// A list of `eval_results_*.json` files
    eval_files: Vec<PathBuf>,
}

impl CliArgs {
    /// Return batches of files which need to be processed together.
    fn files(&self) -> Vec<Vec<PathBuf>> {
        Location::logical_dsts()
            .into_iter()
            .map(|logical_dst| {
                self.eval_files
                    .iter()
                    .filter(|path| {
                        path.as_os_str()
                            .to_string_lossy()
                            .contains(&self.configuration)
                            && path
                                .file_name()
                                .map(|name| name.to_string_lossy().contains(logical_dst))
                                .unwrap_or(false)
                    })
                    .cloned()
                    .collect()
            })
            .collect()
    }

    /// Return the list of test_lengths for which optimization should be performed
    fn param_test_length(&self) -> [u8; 3] {
        [8, 24, 72]
    }

    /// Return the list of low_pass for which optimization should be performed
    fn param_low_pass(&self) -> [u32; 4] {
        [128, 512, 2048, 8192]
    }
}

#[derive(Debug, PartialEq, Eq, PartialOrd, Ord)]
struct TrainTestConfig {
    pub train_length: u8,
    pub test_length: u8,
}
#[derive(Debug, PartialEq, Eq, PartialOrd, Ord, serde::Serialize, serde::Deserialize)]
struct AlgorithmParameters {
    pub train_length: u8,
    pub min_active: u8,
    pub min_pkts_avg: u32,
    pub low_pass: u32,
    pub above_train_limit: u8,
}

fn main() -> Result<()> {
    color_eyre::install()?;
    env_logger::init();
    let args: CliArgs = clap::Parser::parse();

    std::thread::scope(|scope| {
        let dfc = scope.spawn(|| day_forward_chaining(&args));
        let global = scope.spawn(|| global_param_opt(&args));
        dfc.join()
            .map_err(|_| eyre!("Thread day_forward_chaining failed"))??;
        global
            .join()
            .map_err(|_| eyre!("Thread global_param_opt failed"))??;
        ok(())
    })?;
    Ok(())
}

/// Global Parameter Optimization
///
/// For each parameter combination, we search for the combination with the lowest FPR.
/// The test_length, low_pass, and attack_bandwidth parameters are pre-fixed.
fn global_param_opt(args: &CliArgs) -> Result<()> {
    let mut global_opt_results = Vec::new();

    for filebatch in args.files() {
        let mut attack_bandwidth: u64 = 0;
        let mut eval_results: Vec<(DataConfiguration<()>, EvaluationResults)> = Vec::new();

        for file in filebatch {
            attack_bandwidth = file
                .to_string_lossy()
                .split("bps")
                .next()
                .unwrap()
                .rsplit('_')
                .next()
                .unwrap()
                .parse()
                .unwrap();

            let res: Vec<(DataConfiguration<()>, EvaluationResults)> = {
                let data = std::fs::read_to_string(&file)?;
                serde_json::from_str(&data)?
            };
            eval_results.extend(res);
        }

        dbg!(attack_bandwidth);
        dbg!(eval_results.len());

        // Extract logical destination
        let location;
        let iprange_dst;
        {
            let dc = &eval_results.first().unwrap().0;
            location = dc.location;
            iprange_dst = dc.iprange_dst;
        }

        #[allow(clippy::type_complexity)]
        let mut precomputed: BTreeMap<
            /* test_length, low_pass */ (u8, u32),
            BTreeMap<
                AlgorithmParameters,
                BTreeMap</* Window Start */ u32, (DataConfiguration<()>, EvaluationResults)>,
            >,
        > = Default::default();

        for (config, results) in eval_results {
            let algo_params = AlgorithmParameters {
                train_length: config.train_length,
                min_active: config.min_active,
                min_pkts_avg: config.min_pkts_avg,
                low_pass: config.low_pass,
                above_train_limit: config.above_train_limit.round() as u8,
            };
            precomputed
                .entry((config.test_length, config.low_pass))
                .or_default()
                .entry(algo_params)
                .or_default()
                .insert(config.window_start, (config, results));
        }
        let precomputed = &precomputed;

        global_opt_results.par_extend(args.param_test_length().into_par_iter().flat_map(
            move |test_length| {
                args.param_low_pass().into_par_iter().map(move |low_pass| {
                    println!("Test Length: {test_length}, Low Pass {low_pass}");

                    let mut best_params = None;
                    let mut best_avg_fpr = f64::INFINITY;
                    let mut best_avg_attack_traffic = f64::INFINITY;

                    precomputed
                        .get(&(test_length, low_pass))
                        .unwrap()
                        .iter()
                        .for_each(|(params, eval_results)| {
                            let mut train_time = 1_u32;
                            let mut fprs = Vec::new();
                            let mut attack_traffic = Vec::new();

                            while let Some(eval_result) = eval_results.get(&train_time) {
                                fprs.push(eval_result.1.fpr());
                                attack_traffic.push(eval_result.1.false_negatives);

                                train_time += test_length as u32;
                            }

                            let avg_fpr = fprs.iter().cloned().sum::<f64>() / fprs.len() as f64;
                            if avg_fpr < best_avg_fpr {
                                let avg_attack_traffic = attack_traffic.iter().cloned().sum::<f64>()
                                    as f64
                                    / attack_traffic.len() as f64;

                                best_avg_fpr = avg_fpr;
                                best_params = Some(params);
                                best_avg_attack_traffic = avg_attack_traffic;
                            }
                        });

                    serde_json::json!({
                        "location": location,
                        "iprange_dst": iprange_dst,

                        "attack_bandwidth": attack_bandwidth,
                        "test_length": test_length,
                        "low_pass": low_pass,

                        "avg_fpr": best_avg_fpr,
                        "avg_attack_traffic": best_avg_attack_traffic,

                        "best_params": best_params.unwrap(),
                    })
                })
            },
        ));
    }

    let extra = match &args.extra {
        Some(extra) => format!("_{}", extra),
        None => String::new(),
    };
    std::fs::write(
        format!(
            "./global_opt_results_{configuration}{extra}.json",
            configuration = args.configuration
        ),
        serde_json::to_string(&global_opt_results)?,
    )?;

    Ok(())
}

/// Compute the average FPR/traffic
fn day_forward_chaining(args: &CliArgs) -> Result<()> {
    // For Day Forward Chaining we need the corresponding entries for a specific configuration.
    // The start times are increasing by the test window size.
    // This ensures that we are "jumping" through the time series in non-overlapping test windows.
    //
    // The experiment can be done multiple times, i.e., by shifting the first start time.
    // This will overlap with other start times, but the series itself will create non-overlapping test windows.
    // For a test window size of `n` there can be `n` different start times, i.e., x mod n.
    //
    // Each logical location (location + dst IP) will be analysed separately.
    // We can pin the attack bandwidth to a single value. The attack bandwidth is mainly ineffective, as the final bandwidth is mainly determined by the low pass filter.
    //
    // For example:
    // start time: x
    // train window size: train
    // test window size: test
    //
    // Train on [x, x + train) and validate on [x + train, x + train + test).
    // Choose the best parameters for the validation set.
    // The test uses a new trainging on [x + test, x + train + test).
    // Then, the test results are computed on on [x + train + test, x + train + test + test
    //
    // This describes the simplified case with a fixed training interval.
    // The training interval can also be optimized.
    // For this we fix the test start time and compute everything relative to it.
    //
    // For example:
    // test time: x
    // train window size: train
    // test window size: test
    //
    // Train on [x - train - test, x - test) and validate on [x - test, x).
    // Compute the results while training on [x - train, x) and testing on [x, x + test).
    let mut dfc_results = Vec::new();

    for filebatch in args.files() {
        let mut attack_bandwidth: u64 = 0;
        let mut eval_results: Vec<(DataConfiguration<()>, EvaluationResults)> = Vec::new();

        for file in filebatch {
            attack_bandwidth = file
                .to_string_lossy()
                .split("bps")
                .next()
                .unwrap()
                .rsplit('_')
                .next()
                .unwrap()
                .parse()
                .unwrap();

            let res: Vec<(DataConfiguration<()>, EvaluationResults)> = {
                let data = std::fs::read_to_string(&file)?;
                serde_json::from_str(&data)?
            };
            eval_results.extend(res);
        }

        dbg!(attack_bandwidth);
        dbg!(eval_results.len());

        // Extract logical destination
        let location;
        let iprange_dst;
        {
            let dc = &eval_results.first().unwrap().0;
            location = dc.location;
            iprange_dst = dc.iprange_dst;
        }

        #[allow(clippy::type_complexity)]
        let mut precomputed: BTreeMap<
            // (test_length, low_pass)
            (u8, u32),
            BTreeMap<
                // test_start
                u32,
                BTreeMap<AlgorithmParameters, (DataConfiguration<()>, EvaluationResults)>,
            >,
        > = Default::default();

        for (config, results) in eval_results {
            let algo_params = AlgorithmParameters {
                train_length: config.train_length,
                min_active: config.min_active,
                min_pkts_avg: config.min_pkts_avg,
                low_pass: config.low_pass,
                above_train_limit: config.above_train_limit.round() as u8,
            };
            precomputed
                .entry((config.test_length, config.low_pass))
                .or_default()
                .entry(config.window_start + config.train_length as u32)
                .or_default()
                .insert(algo_params, (config, results));
        }
        let precomputed = &precomputed;

        dfc_results.par_extend(
            args.param_test_length()
                .into_par_iter()
                .flat_map(|test_length| {
                    args.param_low_pass().into_par_iter().map(move |low_pass| {
                        println!("Test Length: {test_length}, Low Pass {low_pass}");

                        // Prevent underflows by not starting from 1
                        let mut test_time = 1_u32 + test_length as u32;
                        let mut fprs = Vec::new();
                        let mut attack_traffic = Vec::new();
                        loop {
                            // Train on [x - train - test, x - test) and validate on [x - test, x).
                            // Compute the results while training on [x - train, x) and testing on [x, x + test).
                            let train_test_results =
                                precomputed.get(&(test_length, low_pass)).unwrap();
                            // Break after iterating through all possible times
                            if test_time > *train_test_results.keys().last().unwrap() {
                                break;
                            }

                            if let (Some(validation_results), Some(test_results)) = (
                                train_test_results.get(&(test_time - test_length as u32)),
                                train_test_results.get(&test_time),
                            ) {
                                // Find the best parameters for the validation set.
                                let best_algo_params = validation_results
                                    .iter()
                                    .max_by(|l, r| l.1 .1.fpr().total_cmp(&r.1 .1.fpr()).reverse())
                                    .expect("The list of validation results must never be empty")
                                    .0;
                                // Run on test data with the best parameters.
                                let (_test_config, test_results) = test_results
                                    .get(best_algo_params)
                                    .expect("The test results must contain the best parameters");
                                fprs.push(test_results.fpr());
                                attack_traffic.push(test_results.false_negatives);
                            }
                            test_time += test_length as u32;
                        }
                        let avg_fpr = fprs.iter().cloned().sum::<f64>() / fprs.len() as f64;
                        let avg_attack_traffic = attack_traffic.iter().cloned().sum::<f64>() as f64
                            / attack_traffic.len() as f64;
                        serde_json::json!({
                            "location": location,
                            "iprange_dst": iprange_dst,

                            "attack_bandwidth": attack_bandwidth,
                            "test_length": test_length,
                            "low_pass": low_pass,

                            "avg_fpr": avg_fpr,
                            "avg_attack_traffic": avg_attack_traffic
                        })
                    })
                }),
        );
    }

    let extra = match &args.extra {
        Some(extra) => format!("_{}", extra),
        None => String::new(),
    };
    std::fs::write(
        format!(
            "./dfc_results_{configuration}{extra}.json",
            configuration = args.configuration
        ),
        serde_json::to_string(&dfc_results)?,
    )?;

    Ok(())
}
